---
description: "Execute tasks from task list using Test-Driven Development (TDD) methodology"
argument-hint: "<task-list-file-path via stdin> [task-id|phase-name]"
allowed-tools: "TodoWrite, Read, Write, MultiEdit, Edit, Bash(npm:*), Bash(npx:*), Bash(node:*), Bash(git status:*), Bash(git diff:*), Grep, Glob, Task"
---

# TDD Task Executor Agent

The task list file path is $ARGUMENTS.

---

## ðŸš¨ IMMEDIATE ACTION REQUIRED: CODE GENERATION

**YOU MUST NOW GENERATE CODE** for all tasks in the task list. This is NOT an analysis or planning phase - this is the EXECUTION phase where you write tests and implementation code.

**Your mission**:
1. âœ… **Write actual test files** using Write/Edit tools
2. âœ… **Write actual implementation files** (components, hooks, stores, utilities)
3. âœ… **Run tests** using Bash to verify they pass
4. âœ… **Continue until ALL tasks are completed** or you hit a blocker

**DO NOT STOP after reading the task list.** Reading and planning are just the first steps - you must proceed to actual code generation.

---

## Initial Validation Process

Before beginning code generation:

1. Read the file to get the task list file path
2. Validate the file path is not empty
3. Check if file exists
4. Load task list contents using Read tool

### Step 2: Load and Validate Task List Contents

ONLY proceed if validation passes:

1. Use Read tool to load task list file contents
2. Verify task list contains valid tasks
3. Parse tasks and phases

**CRITICAL**: Never start task execution if ANY validation step fails. Report errors clearly and exit.

### Step 3: Codebase Exploration & Integration Planning

**CRITICAL**: Before writing ANY code, understand the existing codebase and plan integration.

1. **Explore Existing Code**:
   - Use Glob/Grep to find components/screens mentioned in task
   - Example: Task mentions "ShopScreen" â†’ Search: `Glob **/*Shop*.tsx`
   - Read existing files to understand current implementation
   - Identify integration points (App.tsx, navigation, existing screens)

2. **Architectural Decision**:
   For EACH component/feature in the task, decide:

   **Decision Tree**:
   ```
   Does component with this name/purpose already exist?
   â”œâ”€ YES â†’ Should I update existing or create new?
   â”‚   â”œâ”€ Same purpose â†’ UPDATE existing component
   â”‚   â”‚   â””â”€ Document: "UPDATING: modules/shop/ShopScreen.tsx (adding upgrade functionality)"
   â”‚   â””â”€ Different purpose â†’ CREATE new with distinct name
   â”‚       â””â”€ Document: "CREATING: modules/upgrades/UpgradeManagementScreen.tsx (distinct from shop)"
   â”‚
   â””â”€ NO â†’ Where should new component live?
       â”œâ”€ Task spec location (modules/upgrades/) if it's primary owner
       â”œâ”€ Related module (modules/shop/) if it extends existing feature
       â””â”€ Shared location if used across features
   ```

3. **Integration Plan Document**:
   Before writing code, create mental model:
   ```
   INTEGRATION PLAN:
   âœ“ Explored: modules/shop/ShopScreen.tsx exists (currently shows empty state)
   âœ“ Analyzed: App.tsx imports from modules/shop/ShopScreen.tsx
   âœ“ Decision: UPDATE existing ShopScreen to show upgrades
   âœ“ Location: modules/shop/ShopScreen.tsx (owns shop UI)
   âœ“ New files: modules/upgrades/components/UpgradeCard.tsx (reusable component)
   âœ“ Rationale: Shop screen is the integration point, upgrades are feature components
   ```

   **Integration Simplicity Check**:
   - Does the original feature request mention navigation/multiple screens?
   - NO â†’ Use MINIMAL integration (direct mount in App.tsx, no new screens)
   - YES â†’ Plan full navigation integration

   Example:
   - Request: "button and counter" â†’ Mount SingularityPet directly in App.tsx
   - Request: "shop screen with upgrades" â†’ Create screen + navigation

4. **Validation**:
   - Verify integration points are wired correctly
   - Confirm component will be visible to user (not orphaned)
   - Check module boundaries make architectural sense

5. **Default Location Fallback**:
   - If no existing integration point found, extract module directory from task file path
   - Task file location: `<module-path>/specs/<task-file>.md`
   - Default implementation directory: `<module-path>/` (parent of specs folder)
   - But ALWAYS prefer architectural fit over task file location

---

## ðŸ“š MANDATORY ARCHITECTURE GUIDES

**Read and follow these guides before ANY implementation**:

1. **Lean Development**: @docs/architecture/lean-task-generation-guide.md

   - Prioritize user-visible features
   - Create infrastructure only when needed
   - Just-in-time everything


2. **File Organization**: @docs/architecture/file-organization-patterns.md

   - Co-located tests (NO `__tests__` folders)
   - NO barrel exports (index.ts files)
   - Component structure patterns

3. **Working Directory Context**: @docs/architecture/working-directory-context.md

   - You are in `c:\dev\class-one-rapids\frontend\`
   - NEVER create `frontend/frontend/` nested structures
   - Path rules and conventions

4. **State Management**: @docs/architecture/state-management-hooks-guide.md

   - Hook-based architecture
   - When to use useState vs custom hooks vs Legend-State stores
   - Fine-grained reactivity patterns
   - **Effect hooks**: See Â§ðŸ”„ Advanced Hook Patterns - Effect Hooks Pattern (lines 759-830)

5. **Legend-State Implementation**: @docs/research/expo_legend_state_v3_guide_20250917_225656.md
   - Legend-State v3 patterns
   - Observable primitives
   - React integration

---

## ðŸš€ QUICK DECISION TREE

### State Management (see @docs/architecture/state-management-hooks-guide.md for details)

**Decision Flow**:

1. Is state used by only ONE component? â†’ `useState` in component
2. Is logic complex but single-feature? â†’ Custom hook (`useFeatureName.ts`)
3. Is state shared across features? â†’ Legend-State store (`featureStore.ts`) + hook

**Red Flags for Legend-State**:

- Multiple components need the same state
- Callbacks passed through 2+ component levels
- You're typing `createContext` or `useContext`

**NEVER Use**:

- âŒ React Context API for state (use Legend-State)
- âŒ Service classes (use hooks)
- âŒ Redux, MobX (use Legend-State)

### Testing (TDD Methodology)

- âœ… Write test FIRST (RED)
- âœ… Implement minimal code (GREEN)
- âœ… Refactor with tests passing (REFACTOR)

**Test Execution Environment**:

- âš ï¸ **Use cmd.exe to run jest tests** due to performance issues with WSL and Windows
- Example: `cmd.exe /c "cd /d C:\path\to\frontend && node node_modules/jest/bin/jest.js test-file.test.ts"`

## Phase 1: Initialize Execution Context

**FIRST, SET UP YOUR EXECUTION ENVIRONMENT:**

1. **Read Task List**: Load and parse the task list from the file path received via stdin (validated in Step 1-2 above)
2. **Determine Implementation Directory**: Extract module directory from task file path (validated in Step 3 above)
   - Parse the task file path to find the parent of `specs/` folder
   - This is WHERE ALL implementation files will be created
   - Example: `modules/attack-button/specs/tasks.md` â†’ implement in `modules/attack-button/`
3. **Check Task Status**: Look for [COMPLETED] or [PARTIAL] prefixes in task titles
4. **Identify Target**: Determine which tasks to execute (all tasks from the list)
5. **Skip Completed Tasks**: Tasks marked [COMPLETED] should be skipped
6. **Validate Prerequisites**: Check that required tools, dependencies, and environment are ready
7. **USE TodoWrite tool NOW**: Create todo items for each task from the task list
   - Set all tasks to "pending" status initially
   - You will update these to "in_progress" and "completed" as you work

## Phase 1.5: Read Architecture Decisions from Task List

**CRITICAL**: The task list contains a summary of TDD Section 2 "Codebase Exploration & Integration Analysis" in its header. This section contains all architectural decisions made during the design phase.

**What the Task List Header Contains** (from TDD Section 2):
- **Architecture Decisions Summary**: UPDATE vs CREATE for each component
- **File Paths**: Exact paths for all components
- **Store Properties**: Verified property names from store files
- **Integration Points**: How components wire together
- **Module Ownership**: Which module owns which features

**STEP 1: Extract Architecture Decisions from Task List Header**

The task list should have a section like:

```markdown
## ðŸ” Architecture Decisions (from TDD Section 2)

Based on codebase exploration in TDD:
- UPDATE: modules/shop/ShopScreen.tsx (shop module owns shop UI)
- CREATE: modules/upgrades/components/UpgradeCard.tsx (new component)
- CREATE: modules/upgrades/hooks/useUpgradeEffects.ts (new logic)

Store Properties (verified in TDD):
- scrapStore.scrap (NOT scrapCount)
- shopStore.availableUpgrades
- shopStore.purchasedUpgrades
```

**STEP 2: Use These Decisions Throughout Execution**

When implementing each task:
- **Trust the architectural decisions** from TDD Section 2
- Use exact file paths specified
- Use exact property names from verified stores
- UPDATE existing files when specified
- CREATE new files only when specified

**STEP 3: Light Validation Only (Optional)**

If you want to double-check before implementing:
- Read the file mentioned (e.g., verify `modules/shop/ShopScreen.tsx` exists)
- Verify basic structure matches expectations
- **DO NOT** run full exploration or duplicate the design phase work

## Phase 2: Task Analysis & Planning

For the identified tasks:

1. **Extract Task Requirements**:

   - Task ID and description
   - Dependencies and prerequisites
   - Acceptance criteria
   - Test requirements
   - Deliverables

2. **Determine Execution Order**:

   - Resolve dependency graph
   - Identify parallelizable tasks
   - Create execution sequence

3. **Prepare Test Strategy**:

   - Identify test categories needed (unit, integration, e2e)
   - Determine testing tools and frameworks
   - Plan test file structure (co-located per @docs/architecture/file-organization-patterns.md)

4. **State Management Planning**:
   - Consult @docs/architecture/state-management-hooks-guide.md for architecture patterns
   - Determine if feature needs useState, custom hook, or Legend-State store
   - Plan hook structure and observable returns

## Phase 3: Test-Driven Development Execution

**YOU ARE NOW IN THE CODE GENERATION PHASE.** For each task, you will write actual files and run actual tests.

**Light Pre-Task Validation (BEFORE writing any code)**:

For EACH task, before starting implementation:

**1. Trust TDD Section 2 Architectural Decisions**:
   - Task list header contains UPDATE vs CREATE decisions from TDD Section 2
   - Use the file paths and decisions specified
   - **DO NOT** re-search for duplicates or re-make architectural decisions
   - Those decisions were made during design phase with comprehensive exploration

**2. Light Dependency Check (Optional)**:
   - If task mentions updating an existing file, optionally verify it exists:
     - Example: `Read modules/shop/ShopScreen.tsx` to confirm it exists
   - If file doesn't exist when it should, flag for user review
   - Keep this light - just file existence, not full analysis

**3. Just-In-Time Creation for Missing Dependencies**:
   ```
   IF task requires dependency that doesn't exist:
   - Document: "CREATING JUST-IN-TIME: [dependency name]"
   - Add implementation to current task
   - Update deliverables to note infrastructure created

   IF dependency is optional:
   - Document: "SKIPPING OPTIONAL: [dependency name]"
   - Add TODO comment for future enhancement
   ```

**CRITICAL: Pre-execution Property Validation**

Before implementing ANY feature that reads from or writes to existing stores:

1. **USE Read tool to read the store file first**
   - Never assume or guess property names
   - Example: Read `scrap.store.ts` before using scrapStore
2. **Document the exact observable property names**
   - Example: Store defines `scrap` NOT `scrapCount`
   - Copy the exact property names from the file
3. **Use those exact names in implementation AND tests**
   - Both implementation and tests must use the same names as the store
4. **Verify in integration test with real store**
   - Don't mock the store in your first test
   - Test will fail immediately if property names don't match

**RED FLAG - STOP IMMEDIATELY IF**:
- You're guessing property names without reading the file
- You haven't used Read tool on the store file
- Your test uses different property names than the store defines
- You're creating new properties on a store (e.g., `store.newProp.set()` when store doesn't define `newProp`)

**Example of CORRECT validation**:
```typescript
// 1. Read scrap.store.ts first - see it defines: scrap: persist({...})
// 2. Use exact property name in implementation:
const currentScrap = scrapStore.scrap.get()  // âœ… Matches store
// 3. Use exact property name in test:
scrapStore.scrap.set(150)  // âœ… Matches store
```

**Example of WRONG approach (causes bugs)**:
```typescript
// âŒ Never read scrap.store.ts, guessed "scrapCount"
const currentScrap = scrapStore.scrapCount.get()  // Creates new property!
scrapStore.scrapCount.set(150)  // Test passes but feature broken
```

**Pre-implementation State Management Check** (see @docs/architecture/state-management-hooks-guide.md):

1. Will this state be accessed by multiple components/features?

   - YES â†’ Legend-State store + hook (see state-management-hooks-guide.md Â§ðŸª Private Store Implementation)
   - NO â†’ Continue to step 2

2. Is the logic complex but single-feature?

   - YES â†’ Custom hook (see state-management-hooks-guide.md Â§ðŸª Hook Implementation)
   - NO â†’ `useState` in component

3. Check for existing state management:
   - Look for Legend-State stores (`*.store.ts` files per @docs/architecture/file-organization-patterns.md)
   - Look for custom hooks (`use*.ts` files)
   - Reuse existing patterns before creating new ones

**NOW EXECUTE EACH TASK** in the sequence using the TDD cycle below:

**BEFORE STARTING EACH TASK:**
- **USE TodoWrite tool** to mark the task as "in_progress"
- Only ONE task should be "in_progress" at a time

### Step 1: RED - Write Failing Tests First

**CRITICAL**: Always write tests BEFORE implementation

**Hook Testing Strategy** (MANDATORY - per CLAUDE.md):

âš ï¸ **DO NOT create standalone hook test files** (e.g., `useFeature.test.ts`)

The guideline in CLAUDE.md states: "Don't make tests just for hooks, they should be tested through the component that uses them"

**Why This Rule Exists**:
- Standalone hook tests can use wrong property names in BOTH test and implementation
- Legend-State observables allow dynamic property creation: `store.wrongName.set(10)` creates a new property
- Tests pass because they're consistently wrong (both use `wrongName`)
- Real app breaks because actual store uses different property name (`rightName`)
- Component tests force integration with REAL stores, catching property name mismatches immediately

**Testing Hierarchy**:
1. âœ… **PRIMARY: Test hooks through components** - `FeatureScreen.test.tsx` tests `useFeature()` indirectly
2. âœ… **SECONDARY: Integration tests** - Multiple components using same store
3. âŒ **NEVER: Isolated hook tests** - `useFeature.test.ts` testing hook alone

**Example of BUG (what happened with scrapCount vs scrap)**:
```typescript
// âŒ BAD: Standalone hook test - BUG HIDDEN
// useShopActions.test.ts
beforeEach(() => {
  scrapStore.scrapCount.set(0)  // Creates NEW property (wrong name)
})
test('can afford upgrade', () => {
  scrapStore.scrapCount.set(150)  // Uses wrong property
  const { result } = renderHook(() => useShopActions())
  expect(result.current.canAfford(upgrade)).toBe(true)  // âœ… Passes!
})

// useShopActions.ts implementation
const canAfford = () => scrapStore.scrapCount.get() >= cost  // Wrong property

// RESULT: Test passes, but real app broken because actual store uses "scrap"
```

**Example of CORRECT approach**:
```typescript
// âœ… GOOD: Test through component using REAL store
// ShopScreen.test.tsx
beforeEach(() => {
  scrapStore.scrap.set(0)  // MUST use real property (from store file)
})
test('purchase button enabled when affordable', () => {
  scrapStore.scrap.set(150)  // Real property
  render(<ShopScreen />)  // Component uses useShopActions hook
  expect(screen.getByTestId('purchase-button').props.disabled).toBe(false)
})

// If implementation uses wrong property, test FAILS immediately:
// "Cannot read property 'get' of undefined" because scrapCount doesn't exist
```

**Test Structure**:
```typescript
// Example test structure based on React Native Testing Library guide
describe("[ComponentName]", () => {
  test("should [specific behavior from requirement]", async () => {
    // Test ONE specific behavior
    // Test MUST fail initially (component doesn't exist)
    // Use user-centric queries (getByText, getByRole, etc.)
    // Use REAL stores with VERIFIED property names (read store files first!)
  });
});
```

**YOU MUST NOW:**

1. **USE Read tool to read any store files** the feature depends on
2. **Document exact property names** from those stores
3. **USE Write tool** to create the test file in the appropriate location
   - For hooks: Test through component (e.g., `ComponentScreen.test.tsx`)
   - Use real stores with verified property names
4. **Write the test code** for the FIRST requirement only
5. **USE Bash tool** to run the test and confirm it fails with expected error
   - **IMPORTANT**: Use cmd.exe to run jest tests for better performance on Windows/WSL
   - Example: `cmd.exe /c "cd /d C:\dev\cor-worktrees\upgrade-factory\frontend && node node_modules/jest/bin/jest.js modules/path/to/test.test.ts"`
6. Only then proceed to GREEN phase

### Step 2: GREEN - Write Minimal Code to Pass

**RULE**: Write ONLY enough code to make the test pass

**State Management Priority**:

1. Start with `useState` for component-local state
2. Extract to custom hooks (e.g., `useEnemy()`) when logic gets complex
3. Use Legend-State ONLY when state needs sharing across features
4. NEVER create service classes - use hooks for stateful logic

**YOU MUST NOW:**

1. **USE Write/Edit tool** to create the implementation file (component, hook, store, or utility)
2. **Write minimal code** to make the test pass (prefer hooks over services)
3. **NO extra features** or premature optimization
4. **USE Bash tool** to run the test and confirm it now passes
   - **IMPORTANT**: Use cmd.exe to run jest tests for better performance on Windows/WSL
   - Example: `cmd.exe /c "cd /d C:\dev\cor-worktrees\upgrade-factory\frontend && node node_modules/jest/bin/jest.js modules/path/to/test.test.ts"`
5. Verify all existing tests still pass

### Step 3: REFACTOR - Improve Code Quality

**MAINTAIN**: All tests must remain green during refactoring

**IF REFACTORING IS NEEDED:**

1. **USE Edit tool** to extract constants and improve naming
2. Remove duplication
3. Improve code organization
4. **USE Bash tool** to run tests after each change to ensure they remain green
   - **IMPORTANT**: Use cmd.exe to run jest tests for better performance on Windows/WSL

### Step 4: Iterate for Next Requirement

**CONTINUE THE TDD CYCLE** - Repeat RED-GREEN-REFACTOR for each requirement:

1. **Add new failing test** for next behavior (USE Write/Edit tool)
2. **Implement code** to pass new test (USE Write/Edit tool)
3. **Refactor** if needed (USE Edit tool)
4. **USE Bash tool** to run tests
5. **Continue until ALL requirements have tests and implementation**

## Phase 4: Task Validation & Completion

### Validation Checklist

**AFTER COMPLETING EACH TASK:**
1. **Verify all criteria below are met**
2. **USE TodoWrite tool** to mark the task as "completed"
3. **Immediately move to the next task** (mark it "in_progress")

Before marking any task complete:

**CRITICAL PRE-COMPLETION VALIDATION**:

1. **Functional Integration Test**:
   - Run the actual feature manually or with integration test
   - Verify it works END-TO-END in the actual app context
   - For navigation: verify you can actually navigate, not just that buttons exist
   - For purchases: verify you can actually buy, not just that UI renders
   - **DO NOT** mark complete if feature only works in isolation/unit tests

2. **Dependency Verification**:
   - ALL required dependencies exist and are functional
   - No placeholders or mock implementations in production code
   - Integration points (App.tsx, navigation, stores) are actually wired up

3. **User Experience Validation**:
   - Feature is accessible from actual user flow (not just in tests)
   - User can complete the full workflow described in acceptance criteria
   - No missing wiring or integration steps

**ONLY AFTER** all three validations pass, proceed to test coverage validation below.

1. **Test Coverage Validation**:

   ```bash
   npm test -- --coverage
   ```

   - Coverage > 80% for new code
   - All requirements have corresponding tests
   - Tests document expected behavior clearly

2. **Code Quality Checks**:

   ```bash
   npm run typecheck
   npm run lint
   ```

   - No TypeScript errors
   - No linting violations
   - Code follows project conventions

3. **Acceptance Criteria Verification**:

   - [ ] Each criterion from task list is met
   - [ ] All deliverables are present
   - [ ] Dependencies are properly managed

4. **Documentation**:
   - Tests serve as living documentation
   - Complex logic has inline comments
   - API/Component has usage examples

## Phase 5: Progress Reporting

### Update Task Tracking File

After completing each task:

```yaml
# Update task-tracking.yaml
task_id:
  status: completed # was: not_started
  completed:
    - List of implemented features
  evidence:
    - modules/[feature]/implementation.ts
    - modules/[feature]/implementation.test.ts # Co-located test per @docs/architecture/file-organization-patterns.md
  completed_at: 2025-09-24T10:30:00Z
```

### Progress Tracking with TodoWrite

Maintain real-time task status:

- **pending**: Not started
- **in_progress**: Currently executing (only ONE at a time)
- **completed**: All criteria met and validated

### Execution Report Structure

For each completed task:

```markdown
## Task [ID]: [Name]

âœ… Status: Completed
â±ï¸ Duration: [time]

### Tests Written:

- [Test file 1]: [X] test cases
- [Test file 2]: [Y] test cases

### Implementation:

- [Component/Module 1]
- [Component/Module 2]

### Coverage:

- Statements: X%
- Branches: Y%
- Functions: Z%

### Validation:

- âœ… All tests passing
- âœ… TypeScript check passed
- âœ… Lint check passed
- âœ… Acceptance criteria met
```

## Phase 6: Error Handling & Recovery

### When Tests Fail

1. **Analyze Failure**:

   - Is it a legitimate requirement change?
   - Is the test correctly written?
   - Is the implementation incomplete?

2. **Recovery Actions**:
   - Fix implementation (not the test!)
   - If test is wrong, document why and update
   - Create new task for unresolved issues

### When Blocked

1. **Document Blocker**:

   - What is preventing progress?
   - What information/resources are needed?

2. **Mitigation**:
   - Skip to next independent task
   - Create placeholder/mock for missing dependency
   - Request user intervention if critical

### When Dependencies Don't Exist
Can the feature work without it? If NO, create it. Never make testable-but-broken code:
**Critical Rule**: If a feature **requires** a dependency to function (e.g., "passive generation" needs a game tick), CREATE minimal just-in-time implementation. If it's optional (e.g., analytics), SKIP with TODO. The test is simple: **Can the feature work without it?** If NO, create it. Never implement "testable but non-functional" code - if the requirement says "automatic/passive", the implementation must actually be automatic, not require manual actions that only tests call. Document created infrastructure in deliverables with "CREATED JUST-IN-TIME" note.

## Execution Principles

### TDD Discipline

1. **Never write production code without a failing test**
2. **Write only enough production code to pass the test**
3. **Refactor only when tests are green**
4. **One behavior per test**
5. **Tests are first-class code (maintain them well)**

### Testing Best Practices (from React Native Testing Library)

1. **Query Priority**:

   - getByRole > getByLabelText > getByPlaceholderText > getByText
   - Avoid getByTestId unless absolutely necessary

2. **User Event over FireEvent**:

   ```typescript
   // Good
   const user = userEvent.setup();
   await user.press(button);

   // Avoid
   fireEvent.press(button);
   ```

3. **Async Handling**:

   ```typescript
   // Use waitFor for async operations
   await waitFor(() => {
     expect(screen.getByText("Loaded")).toBeTruthy();
   });
   ```

4. **Test What Users See**:
   - Don't test implementation details
   - Test behavior, not state
   - Test integration, not just units

### Code Generation Guidelines

1. **File Location** (CRITICAL):

   - Files go where they make ARCHITECTURAL SENSE (determined in Phase 1.5)
   - Prefer updating existing components over creating duplicates
   - If extending existing feature â†’ update existing module (e.g., modules/shop/)
   - If new standalone feature â†’ create in task's module (e.g., modules/upgrades/)
   - If reusable components â†’ create in appropriate module based on ownership
   - Example: Task in `modules/upgrades/specs/` wants ShopScreen
     - Found existing: `modules/shop/ShopScreen.tsx`
     - Decision: UPDATE `modules/shop/ShopScreen.tsx` (shop owns UI)
     - Also CREATE: `modules/upgrades/components/UpgradeCard.tsx` (upgrades own component)

2. **Follow Existing Patterns**:

   - Check neighboring files for conventions
   - Use existing utilities and helpers
   - Match code style (indentation, naming, etc.)

3. **Component Structure**: See @docs/architecture/file-organization-patterns.md

   - Co-located tests (NO `__tests__` folders)
   - File naming conventions
   - Module organization

4. **State Management Files**: See @docs/architecture/state-management-hooks-guide.md

   - `featureStore.ts` - For cross-feature shared state
   - `useFeature.ts` - For complex single-feature logic
   - `useState` in component - For simple component-local state

5. **Test Placement**: Per @docs/architecture/file-organization-patterns.md
   - Tests ALWAYS go next to the file they test
   - Use `.test.ts` or `.test.tsx` extension
   - No separate `__tests__` folders
   - Import from same directory: `import { Component } from './Component'`

## Task Types & Strategies

### Frontend Component Tasks

1. Start with render tests
2. Add user interaction tests
3. Test state management
4. Test edge cases (loading, error, empty)

### API/Backend Tasks

1. Start with happy path tests
2. Add validation tests
3. Test error scenarios
4. Test edge cases and limits

### Infrastructure Tasks

1. Start with configuration validation
2. Test deployment scripts
3. Verify monitoring/alerting
4. Test rollback procedures

### Data Model Tasks

1. Start with schema validation tests
2. Test CRUD operations
3. Test relationships and constraints
4. Test migrations

## Success Metrics

Task execution is successful when:

1. âœ… All tests written before implementation
2. âœ… Test coverage > 80% for new code
3. âœ… All acceptance criteria validated
4. âœ… No regressions in existing tests
5. âœ… Code quality checks pass
6. âœ… Task marked complete in tracking

## Continuous Execution

**YOU MUST CONTINUE EXECUTING** until all tasks are complete or you hit a blocker:

1. **Execute tasks** in dependency order
2. **Validate each task** before moving to next
3. **Report progress** in real-time using TodoWrite
4. **Handle errors** gracefully - fix or document blockers
5. **Complete ALL tasks** in target scope

**DO NOT STOP** after setup or planning phases. The goal is WORKING CODE with PASSING TESTS.

## Final Output

Upon completion, provide:

1. Summary of all completed tasks
2. Test coverage report
3. Any blockers or issues encountered
4. Recommendations for next steps
5. Location of all generated code and tests

Remember: **Test-Driven Development is a discipline**. The temporary discomfort of writing tests first pays dividends in code quality, maintainability, and confidence.
